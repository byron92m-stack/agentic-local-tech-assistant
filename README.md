\# Agente Conversacional Técnico Local



Este proyecto implementa un agente conversacional técnico local, diseñado para funcionar como:



\- Asistente de arquitectura

\- Consultor técnico

\- Soporte para debugging y diseño de sistemas

\- Interfaz cognitiva para entornos locales (Windows + WSL)



El agente está pensado como una pieza de infraestructura cognitiva que corre 100% en local, usando modelos LLM locales y una API propia.



\## Objetivos



\- Proveer un agente técnico capaz de razonar sobre:

&nbsp; - Arquitectura de sistemas

&nbsp; - Pipelines de datos

&nbsp; - Entornos híbridos Windows + WSL

\- Mantener todo el flujo en local, sin depender de servicios externos.



\## Tecnologías



\- Python

\- FastAPI

\- Uvicorn

\- LLM local (Ollama u otro backend)

\- WSL2 (Ubuntu)



\## Estado actual



Este repositorio documenta la arquitectura, los prompts y la estructura del agente.  

El foco inicial está en la claridad arquitectónica y la documentación, más que en el despliegue completo.

